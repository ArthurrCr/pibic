{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import tacoreader\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = '../src'\n",
    "os.chdir(folder_path)\n",
    "from dataset.download_data import download_cloudsen12\n",
    "from utils.data_loader import create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos baixados: ['..\\\\data\\\\dados\\\\cloudsen12-l1c.0000.part.taco', '..\\\\data\\\\dados\\\\cloudsen12-l1c.0004.part.taco']\n"
     ]
    }
   ],
   "source": [
    "# Baixar os dados (caso ainda não estejam baixados)\n",
    "parts = download_cloudsen12(local_dir=\"../data/dados\", type = \"L1C\")\n",
    "print(\"Arquivos baixados:\", parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de amostras: 16135\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset\n",
    "ds = tacoreader.load(parts)\n",
    "print(\"Número total de amostras:\", len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tortilla:data_split\n",
      "train         13248\n",
      "test           1715\n",
      "validation     1172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"tortilla:data_split\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A contagem global (47360 train / 1715 test / 1172 validation) é o total de todas as amostras do CloudSEN12+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internal:subfile</th>\n",
       "      <th>tortilla:id</th>\n",
       "      <th>tortilla:file_format</th>\n",
       "      <th>tortilla:data_split</th>\n",
       "      <th>tortilla:offset</th>\n",
       "      <th>tortilla:length</th>\n",
       "      <th>stac:crs</th>\n",
       "      <th>stac:geotransform</th>\n",
       "      <th>stac:raster_shape</th>\n",
       "      <th>stac:time_start</th>\n",
       "      <th>stac:time_end</th>\n",
       "      <th>stac:centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vsisubfile/7235135_1359647,..\\data\\dados\\clou...</td>\n",
       "      <td>s2l1c</td>\n",
       "      <td>GTiff</td>\n",
       "      <td>None</td>\n",
       "      <td>7235135</td>\n",
       "      <td>1359647</td>\n",
       "      <td>EPSG:32719</td>\n",
       "      <td>[502160.0, 10.0, 0.0, 7567380.0, 0.0, -10.0]</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>1.549637e+09</td>\n",
       "      <td>1.549637e+09</td>\n",
       "      <td>POINT (-68.954266 -22.021252)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vsisubfile/8594782_7153,..\\data\\dados\\cloudse...</td>\n",
       "      <td>target</td>\n",
       "      <td>GTiff</td>\n",
       "      <td>None</td>\n",
       "      <td>8594782</td>\n",
       "      <td>7153</td>\n",
       "      <td>EPSG:32719</td>\n",
       "      <td>[502160.0, 10.0, 0.0, 7567380.0, 0.0, -10.0]</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>1.549637e+09</td>\n",
       "      <td>1.549637e+09</td>\n",
       "      <td>POINT (-68.954266 -22.021252)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    internal:subfile tortilla:id  \\\n",
       "0  /vsisubfile/7235135_1359647,..\\data\\dados\\clou...       s2l1c   \n",
       "1  /vsisubfile/8594782_7153,..\\data\\dados\\cloudse...      target   \n",
       "\n",
       "  tortilla:file_format tortilla:data_split  tortilla:offset  tortilla:length  \\\n",
       "0                GTiff                None          7235135          1359647   \n",
       "1                GTiff                None          8594782             7153   \n",
       "\n",
       "     stac:crs                             stac:geotransform stac:raster_shape  \\\n",
       "0  EPSG:32719  [502160.0, 10.0, 0.0, 7567380.0, 0.0, -10.0]        [512, 512]   \n",
       "1  EPSG:32719  [502160.0, 10.0, 0.0, 7567380.0, 0.0, -10.0]        [512, 512]   \n",
       "\n",
       "   stac:time_start  stac:time_end                  stac:centroid  \n",
       "0     1.549637e+09   1.549637e+09  POINT (-68.954266 -22.021252)  \n",
       "1     1.549637e+09   1.549637e+09  POINT (-68.954266 -22.021252)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tacoreader.load(parts)\n",
    "sample = ds.read(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'driver': 'GTiff', 'dtype': 'uint16', 'nodata': 65535.0, 'width': 512, 'height': 512, 'count': 13, 'crs': CRS.from_epsg(32719), 'transform': Affine(10.0, 0.0, 502160.0,\n",
      "       0.0, -10.0, 7567380.0)}\n",
      "Banda 1: dtype=uint16, mínimo=0, máximo=3968\n",
      "Banda 2: dtype=uint16, mínimo=0, máximo=3932\n",
      "Banda 3: dtype=uint16, mínimo=0, máximo=3876\n",
      "Banda 4: dtype=uint16, mínimo=0, máximo=4476\n",
      "Banda 5: dtype=uint16, mínimo=0, máximo=4736\n",
      "Banda 6: dtype=uint16, mínimo=0, máximo=4972\n",
      "Banda 7: dtype=uint16, mínimo=0, máximo=4960\n",
      "Banda 8: dtype=uint16, mínimo=0, máximo=4652\n",
      "Banda 9: dtype=uint16, mínimo=0, máximo=4720\n",
      "Banda 10: dtype=uint16, mínimo=0, máximo=2856\n",
      "Banda 11: dtype=uint16, mínimo=0, máximo=492\n",
      "Banda 12: dtype=uint16, mínimo=0, máximo=6004\n",
      "Banda 13: dtype=uint16, mínimo=0, máximo=4000\n"
     ]
    }
   ],
   "source": [
    "img_path = sample.read(0)\n",
    "with rasterio.open(img_path) as src:\n",
    "    # Exibe os metadados da imagem (incluindo o dtype e o número de bandas)\n",
    "    print(\"Metadata:\", src.meta)\n",
    "    \n",
    "    # Itera sobre cada banda para obter o tipo de dado e o range\n",
    "    for band in range(1, src.count + 1):\n",
    "        band_data = src.read(band)\n",
    "        print(f\"Banda {band}: dtype={band_data.dtype}, mínimo={np.min(band_data)}, máximo={np.max(band_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame: Index(['internal:subfile', 'tortilla:id', 'tortilla:file_format',\n",
      "       'tortilla:data_split', 'tortilla:offset', 'tortilla:length', 'stac:crs',\n",
      "       'stac:geotransform', 'stac:raster_shape', 'stac:time_start',\n",
      "       'stac:time_end', 'stac:centroid', 'rai:ele', 'rai:cisi', 'rai:gdp',\n",
      "       'rai:hdi', 'rai:gmi', 'rai:pop', 'rai:admin0', 'rai:admin1',\n",
      "       'rai:admin2', 'roi_id', 'old_roi_id', 'equi_id', 'equi_zone',\n",
      "       'label_type', 's2_id', 'real_proj_shape', 's2_mean_solar_azimuth_angle',\n",
      "       's2_mean_solar_zenith_angle', 'thick_percentage', 'thin_percentage',\n",
      "       'cloud_shadow_percentage', 'clear_percentage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds)\n",
    "print(\"Colunas do DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinar primeiro em p509** (que possui mais amostras e, portanto, fornece uma diversidade ampla para a rede aprender as classes de nuvem).  \n",
    "**Depois refinar (fine-tuning) com p2000**, pois os patches maiores ajudam a capturar melhor as correlações espaciais entre nuvens e sombras, o que é benéfico especialmente para a detecção de sombras.\n",
    "\n",
    "Em resumo:\n",
    "  \n",
    "**Treino principal em p509**: aproveita-se a grande quantidade de patches com rótulos “high” (além de “scribble” e “nolabel”, se desejar) para uma base sólida.  \n",
    "**Fine-tuning em p2000**: complementa o aprendizado, fornecendo amostras bem maiores, nas quais o modelo pode aprender melhor a relação geométrica entre nuvens e suas sombras.\n",
    "\n",
    "Em termos de implementação, você pode:\n",
    "- Primeiramente carregar apenas p509 (“real_proj_shape=509”) nos seus DataLoaders, treinar até convergência.  \n",
    "- Em seguida, iniciar um treinamento (ou fine-tuning) carregando apenas p2000 (“real_proj_shape=2000”). Nesse ponto, ou você retoma o estado do modelo anterior (carregando o checkpoint da rede treinada em p509) e faz alguns epochs extras, ou congela camadas, ou usa outra estratégia de transferência, conforme a arquitetura e práticas de fine-tuning que preferir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No artigo, os **três tipos de label_type** aparecem descritos assim:\n",
    "\n",
    "**high**  \n",
    "   - Patches com anotações densas (cada pixel é classificado em clear, thick cloud, thin cloud ou cloud shadow).  \n",
    "   - Divididos em train, val, e test.  \n",
    "   - Ideais para **treinamento supervisionado** tradicional, pois cada pixel tem um rótulo confiável.  \n",
    "\n",
    "**scribble**  \n",
    "   - Patches onde apenas um pequeno conjunto de pixels (menos de 5%) foi anotado manualmente, em formato de “rabiscos” (daí o nome scribble).  \n",
    "   - Também divididos em train, val e test.  \n",
    "   - Úteis para **validação** e para experimentos de semi-supervisão, pois oferecem alguma informação de rótulo em poucos pixels, ajudando a corrigir erros em regiões críticas (bordas de nuvem, por exemplo).\n",
    "\n",
    "**nolabel**  \n",
    "   - Patches **sem** anotações humanas.  \n",
    "   - Disponíveis apenas na pasta *train*.  \n",
    "   - O artigo menciona que cada um desses patches recebe uma máscara de nuvens inferida automaticamente pelo modelo UnetMobV2, podendo servir como base para pré-treinamento (pseudo-rótulos) ou para estratégias de aprendizado semi-supervisionado.  \n",
    "\n",
    "Em suma, **“high”** é o principal conjunto supervisionado, **“scribble”** serve como conjunto adicional de validação/treinamento parcial, e **“nolabel”** oferece um grande volume de dados sem anotação manual, mas com máscaras geradas automaticamente para quem quiser explorar técnicas de pseudo-rótulo, auto-treinamento ou aprendizado semi-supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 8490\n",
      "Val samples:   535\n",
      "Test samples:  975\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    parts,\n",
    "    real_proj_shape=509,  # ou 2000 \n",
    "    label_type=\"high\",    # \"scribble\" ou \"nolabel\"\n",
    "    batch_size=8,\n",
    "    num_workers=2\n",
    ")\n",
    "# Verificar quantos batches e a forma dos tensores\n",
    "if train_loader is not None:\n",
    "    for idx, (imgs, masks) in enumerate(train_loader):\n",
    "        print(f\"Lote {idx}: imagens={imgs.shape}, máscaras={masks.shape}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pibic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
