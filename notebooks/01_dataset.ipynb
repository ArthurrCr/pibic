{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '../src'\n",
    "os.chdir(folder_path)\n",
    "from dataset_utils.download_data import download_cloudsen12plus\n",
    "from utils.data_loader import create_dataloaders\n",
    "import tacoreader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos baixados: ['..\\\\data\\\\dados\\\\cloudsen12-l1c.0000.part.taco', '..\\\\data\\\\dados\\\\cloudsen12-l1c.0004.part.taco']\n"
     ]
    }
   ],
   "source": [
    "# Baixar os dados (caso ainda não estejam baixados)\n",
    "parts = download_cloudsen12plus(local_dir=\"../data/dados\", type = \"L1C\")\n",
    "print(\"Arquivos baixados:\", parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de amostras: 16135\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset\n",
    "ds = tacoreader.load(parts)\n",
    "print(\"Número total de amostras:\", len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tortilla:data_split\n",
      "train         13248\n",
      "test           1715\n",
      "validation     1172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"tortilla:data_split\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A contagem global (47360 train / 1715 test / 1172 validation) é o total de todas as amostras do CloudSEN12+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['internal:subfile', 'tortilla:id', 'tortilla:file_format',\n",
      "       'tortilla:data_split', 'tortilla:offset', 'tortilla:length', 'stac:crs',\n",
      "       'stac:geotransform', 'stac:raster_shape', 'stac:time_start',\n",
      "       'stac:time_end', 'stac:centroid', 'rai:ele', 'rai:cisi', 'rai:gdp',\n",
      "       'rai:hdi', 'rai:gmi', 'rai:pop', 'rai:admin0', 'rai:admin1',\n",
      "       'rai:admin2', 'roi_id', 'old_roi_id', 'equi_id', 'equi_zone',\n",
      "       'label_type', 's2_id', 'real_proj_shape', 's2_mean_solar_azimuth_angle',\n",
      "       's2_mean_solar_zenith_angle', 'thick_percentage', 'thin_percentage',\n",
      "       'cloud_shadow_percentage', 'clear_percentage'],\n",
      "      dtype='object')\n",
      "                                       internal:subfile  \\\n",
      "1498  /vsisubfile/10460113754_1437347,..\\data\\dados\\...   \n",
      "1499  /vsisubfile/10461551101_1288233,..\\data\\dados\\...   \n",
      "1500  /vsisubfile/10462839334_1437179,..\\data\\dados\\...   \n",
      "1501  /vsisubfile/10464276513_1504849,..\\data\\dados\\...   \n",
      "1502  /vsisubfile/10465781362_1501969,..\\data\\dados\\...   \n",
      "\n",
      "                                            tortilla:id tortilla:file_format  \\\n",
      "1498  ROI_00001__20190212T142031_20190212T143214_T19FDF             TORTILLA   \n",
      "1499  ROI_00001__20190304T142031_20190304T142654_T19FDF             TORTILLA   \n",
      "1500  ROI_00001__20190316T141049_20190316T142437_T19FDF             TORTILLA   \n",
      "1501  ROI_00001__20190525T141059_20190525T142053_T19FDF             TORTILLA   \n",
      "1502  ROI_00001__20200308T141731_20200308T143551_T19FDF             TORTILLA   \n",
      "\n",
      "     tortilla:data_split  tortilla:offset  tortilla:length    stac:crs  \\\n",
      "1498                test      10460113754          1437347  EPSG:32719   \n",
      "1499                test      10461551101          1288233  EPSG:32719   \n",
      "1500                test      10462839334          1437179  EPSG:32719   \n",
      "1501                test      10464276513          1504849  EPSG:32719   \n",
      "1502                test      10465781362          1501969  EPSG:32719   \n",
      "\n",
      "                                 stac:geotransform stac:raster_shape  \\\n",
      "1498  [440030.0, 10.0, 0.0, 4573910.0, 0.0, -10.0]        [512, 512]   \n",
      "1499  [440030.0, 10.0, 0.0, 4573910.0, 0.0, -10.0]        [512, 512]   \n",
      "1500  [440030.0, 10.0, 0.0, 4573910.0, 0.0, -10.0]        [512, 512]   \n",
      "1501  [440030.0, 10.0, 0.0, 4573910.0, 0.0, -10.0]        [512, 512]   \n",
      "1502  [440030.0, 10.0, 0.0, 4573910.0, 0.0, -10.0]        [512, 512]   \n",
      "\n",
      "      stac:time_start  ...  equi_zone label_type  \\\n",
      "1498     1.549982e+09  ...         SA       high   \n",
      "1499     1.551710e+09  ...         SA       high   \n",
      "1500     1.552746e+09  ...         SA       high   \n",
      "1501     1.558794e+09  ...         SA       high   \n",
      "1502     1.583678e+09  ...         SA       high   \n",
      "\n",
      "                                                  s2_id  real_proj_shape  \\\n",
      "1498  S2A_MSIL1C_20190212T142031_N0207_R010_T19FDF_2...              509   \n",
      "1499  S2A_MSIL1C_20190304T142031_N0207_R010_T19FDF_2...              509   \n",
      "1500  S2B_MSIL1C_20190316T141049_N0207_R110_T19FDF_2...              509   \n",
      "1501  S2B_MSIL1C_20190525T141059_N0207_R110_T19FDF_2...              509   \n",
      "1502  S2A_MSIL1C_20200308T141731_N0209_R010_T19FDF_2...              509   \n",
      "\n",
      "      s2_mean_solar_azimuth_angle  s2_mean_solar_zenith_angle  \\\n",
      "1498                    50.052448                   44.778064   \n",
      "1499                    44.599861                   38.733580   \n",
      "1500                    43.830052                   33.774744   \n",
      "1501                    30.856044                   14.175443   \n",
      "1502                    43.215801                   37.216397   \n",
      "\n",
      "      thick_percentage  thin_percentage cloud_shadow_percentage  \\\n",
      "1498                 0               32                       0   \n",
      "1499                15                0                      81   \n",
      "1500                54                0                      18   \n",
      "1501                25               23                      10   \n",
      "1502                 0                0                       0   \n",
      "\n",
      "     clear_percentage  \n",
      "1498               68  \n",
      "1499                4  \n",
      "1500               28  \n",
      "1501               42  \n",
      "1502              100  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "ds = tacoreader.load(parts)\n",
    "df = pd.DataFrame(ds)\n",
    "print(df.columns)  \n",
    "print(df.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinar primeiro em p509** (que possui mais amostras e, portanto, fornece uma diversidade ampla para a rede aprender as classes de nuvem).  \n",
    "**Depois refinar (fine-tuning) com p2000**, pois os patches maiores ajudam a capturar melhor as correlações espaciais entre nuvens e sombras, o que é benéfico especialmente para a detecção de sombras.\n",
    "\n",
    "Em resumo:\n",
    "  \n",
    "**Treino principal em p509**: aproveita-se a grande quantidade de patches com rótulos “high” (além de “scribble” e “nolabel”, se desejar) para uma base sólida.  \n",
    "**Fine-tuning em p2000**: complementa o aprendizado, fornecendo amostras bem maiores, nas quais o modelo pode aprender melhor a relação geométrica entre nuvens e suas sombras.\n",
    "\n",
    "Em termos de implementação, você pode:\n",
    "- Primeiramente carregar apenas p509 (“real_proj_shape=509”) nos seus DataLoaders, treinar até convergência.  \n",
    "- Em seguida, iniciar um treinamento (ou fine-tuning) carregando apenas p2000 (“real_proj_shape=2000”). Nesse ponto, ou você retoma o estado do modelo anterior (carregando o checkpoint da rede treinada em p509) e faz alguns epochs extras, ou congela camadas, ou usa outra estratégia de transferência, conforme a arquitetura e práticas de fine-tuning que preferir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No artigo, os **três tipos de label_type** aparecem descritos assim:\n",
    "\n",
    "**high**  \n",
    "   - Patches com anotações densas (cada pixel é classificado em clear, thick cloud, thin cloud ou cloud shadow).  \n",
    "   - Divididos em train, val, e test.  \n",
    "   - Ideais para **treinamento supervisionado** tradicional, pois cada pixel tem um rótulo confiável.  \n",
    "\n",
    "**scribble**  \n",
    "   - Patches onde apenas um pequeno conjunto de pixels (menos de 5%) foi anotado manualmente, em formato de “rabiscos” (daí o nome scribble).  \n",
    "   - Também divididos em train, val e test.  \n",
    "   - Úteis para **validação** e para experimentos de semi-supervisão, pois oferecem alguma informação de rótulo em poucos pixels, ajudando a corrigir erros em regiões críticas (bordas de nuvem, por exemplo).\n",
    "\n",
    "**nolabel**  \n",
    "   - Patches **sem** anotações humanas.  \n",
    "   - Disponíveis apenas na pasta *train*.  \n",
    "   - O artigo menciona que cada um desses patches recebe uma máscara de nuvens inferida automaticamente pelo modelo UnetMobV2, podendo servir como base para pré-treinamento (pseudo-rótulos) ou para estratégias de aprendizado semi-supervisionado.  \n",
    "\n",
    "Em suma, **“high”** é o principal conjunto supervisionado, **“scribble”** serve como conjunto adicional de validação/treinamento parcial, e **“nolabel”** oferece um grande volume de dados sem anotação manual, mas com máscaras geradas automaticamente para quem quiser explorar técnicas de pseudo-rótulo, auto-treinamento ou aprendizado semi-supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 8490\n",
      "Val samples:   535\n",
      "Test samples:  975\n",
      "Lote 0: imagens=torch.Size([8, 13, 512, 512]), máscaras=torch.Size([8, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    parts,\n",
    "    real_proj_shape=509,  # ou 2000 \n",
    "    label_type=\"high\",    # \"scribble\" ou \"nolabel\"\n",
    "    batch_size=8,\n",
    "    num_workers=2\n",
    ")\n",
    "# Verificar quantos batches e a forma dos tensores\n",
    "if train_loader is not None:\n",
    "    for idx, (imgs, masks) in enumerate(train_loader):\n",
    "        print(f\"Lote {idx}: imagens={imgs.shape}, máscaras={masks.shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- subconjunto (8490 train / 535 val / 975 test) surge depois que aplica os filtros para:\n",
    "\n",
    "    - real_proj_shape = 509 (ou seja, p509, descartando os patches de 2000×2000)\n",
    "    - label_type = \"high\" (descartando scribble e nolabel)\n",
    "    - tortilla:data_split in {\"train\", \"validation\", \"test\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geralmente, a ordem (para o Sentinel-2 L1C) é a seguinte:\n",
    "\n",
    "B1: Coastal Aerosol\n",
    "\n",
    "B2: Blue\n",
    "\n",
    "B3: Green\n",
    "\n",
    "B4: Red\n",
    "\n",
    "B5: Vegetation Red Edge 1\n",
    "\n",
    "B6: Vegetation Red Edge 2\n",
    "\n",
    "B7: Vegetation Red Edge 3\n",
    "\n",
    "B8: NIR\n",
    "\n",
    "B8A: Narrow NIR\n",
    "\n",
    "B9: Water Vapor\n",
    "\n",
    "B10: Cirrus\n",
    "\n",
    "B11: SWIR 1\n",
    "\n",
    "B12: SWIR 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pibic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
